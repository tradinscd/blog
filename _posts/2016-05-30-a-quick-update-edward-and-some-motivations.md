---
layout: post
title: 'A quick update: Edward, and some motivations'
date: '2016-05-30 19:15:08'
---

<!--
This blog has been inactive in the past few months; so to give a quick update—and also to build my own momentum for continuing to write—I'll add some short thoughts.
-->

As you may (or may not) know, I've been busy lately spear-heading [Edward](https://github.com/blei-lab/edward), an open-source library for probabilistic modeling. It's meant to help bridge the gap between what I view as two dichotomous approaches of statistical learning: one approach develops complex models in order to achieve the best results on a specific task; and the other approach adheres to simple models in order to understand every component of the analysis both empirically and theoretically. The former starts at the end-goal; the latter starts at the foundation. 

There are many names you can append to one of these approaches, and certainly those names imply contrasting motivations due to culture, and thus contrasting views and contrasting applications. But ultimately, the goal is still the same. The approaches are not orthogonal, but a lack of awareness connecting the two make them seem to be. A neural network is a powerful aproach for modeling non-linear functions (I mean this not tongue-in-cheek; it's difficult to summarize many decades of innovation in a sentence). A Bayesian linear model is a powerful approach for incorporating parameter uncertainty during supervision, and for accessing a basis on which to validate our models.

How do we [assess model fit](https://www.stat.washington.edu/raftery/Research/PDF/Gneiting2007jasa.pdf) from a complex neural network architecture, and [generalize to any setting](http://arxiv.org/abs/1206.6471), whether it be [small data](https://sites.google.com/site/dataefficientml/), [simulation-based tasks](https://sites.google.com/site/dlworkshop16/), or [even causal inferences](http://steinhardt.nyu.edu/priism/newsandevents/conferences)? How do we build [more expressive models](http://link.springer.com/book/10.1007/978-1-4612-0745-0) when [our](http://authors.library.caltech.edu/13796/1/MACnc92d.pdf) [tools](http://www.stat.columbia.edu/~gelman/research/published/A6n41.pdf) tell us the generalized linear model fits okay, but is not nearly as fine-grained as we'd like it to be, or let our inferences [scale](http://leon.bottou.org/publications/pdf/compstat-2010.pdf) to data that no longer fits in memory? If we use the [many](https://en.wikipedia.org/wiki/Long_short-term_memory) [innovations](http://www.gatsby.ucl.ac.uk/~dayan/papers/hm95.pdf) of deep learning in concert with statistical analysis, or conversely, the [century of statistical foundations](https://en.wikipedia.org/wiki/Statistical_Methods_for_Research_Workers) in deep learning, we might just achieve something quite grand. (And I mean this one only a little tongue-in-cheek.)

Edward, broadly speaking, tries to combine efforts from both approaches. It's a software library I've always wanted to develop but never had the right resources until now. Fast and distributed computation can be done using [TensorFlow](https://www.tensorflow.org) as a rich symbolic framework. Neural networks can be easily constructed with high-level libraries like [Keras](http://keras.io).  Flexible probability models can be specified using languages such as [Stan](http://mc-stan.org). And all of inference can be done using fast approximations via a built-in variational inference engine, with criticism techniques for both point prediction and distribution-based model assessments.

I gave an Edward talk a few days ago at Google Brain— which I quite positively butchered due to a lack of sleep and preparation. (If only I had known I would get a sizeable cast of the TensorFlow core developers, Geoff Hinton, Jeff Dean, and Kevin Murphy in one room!) But I think the work explained itself, and with a lot of excitement about why Bayesian deep learning might be the right thing.

There are a number of necessary developments in Edward to even make small steps in connecting these two approaches. I finally got to refactoring the code for [variational auto-encoders](https://github.com/blei-lab/edward/blob/master/examples/convolutional_vae.py); and designing the [criticism API](https://github.com/blei-lab/edward/pull/107) for posterior predictive checks; and getting [much help from others](http://cbonnett.github.io/MDN_EDWARD_KERAS_TF.html) for explaining how to build neural network-based probabilistic models; and many open problems to [try](http://dustintran.com/papers/TranRanganathBlei2016.pdf) [to](http://arxiv.org/abs/1603.00788) [solve](http://arxiv.org/abs/1511.02386). It's not even close to there for getting statisticians, machine learners, and deep learners to agree with one another. But I think Edward is making progress.